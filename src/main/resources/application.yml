spring:
  application:
    name: spring-ai-ollama-demo
  ai:
    ollama:
      base-url: ${OLLAMA_HOST:http://localhost:11434}
      model: mistral
      options:
        temperature: 1.0
        top_p: 0.95
        top_k: 64
        repeat_penalty: 1.0
        num_ctx: 4096
        num_predict: 256
        stop: ["</s>", "USER:", "ASSISTANT:"]
        num_batch: 512
        num_gpu: 1
        num_thread: 8
        num_keep: 48
        seed: -1
        mirostat: 2
        mirostat_tau: 5.0
        mirostat_eta: 0.1
        rope_freq_base: 10000
        rope_freq_scale: 1.0
        num_gqa: 8
        rms_norm_eps: 1e-5
        logits_all: false
        vocab_only: false
        use_mmap: true
        use_mlock: false
        embedding: false
        rope_scaling:
          type: linear
          factor: 2.0
  # Datasource and JPA configurations are now profile-specific
  # See application-dev.yml (SQLite) and application-prod.yml (Oracle)

# Logging Configuration
logging:
  level:
    root: INFO
    com.example: DEBUG # Default level, can be overridden by profiles
    com.zaxxer.hikari: INFO
    # Profile-specific logging for Hibernate SQL

# Server Configuration
server:
  port: 8080

# Async Executor Configuration
app:
  async:
    corePoolSize: 2
    maxPoolSize: 5
    queueCapacity: 10
    threadNamePrefix: TestGenTask-

# Info endpoint configuration (optional)
info:
  app:
    name: ${spring.application.name}
    description: Spring AI Demo Application with Ollama Integration
    version: "@project.version@"

# Application specific properties
api:
  security:
    key: "YOUR_SECURE_API_KEY_HERE" # TODO: Replace with a strong, securely managed key
 